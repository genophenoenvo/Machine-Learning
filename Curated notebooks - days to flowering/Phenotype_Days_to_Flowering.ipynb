{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Phenotype: Days to Flowering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CxpxkDVsb7j"
      },
      "source": [
        "# **Phenotype Prediction: Days to Flowering**\n",
        "\n",
        "The phenotype of an organism is the result of an interplay betweeen its genetic composition and the environment. Due to the gradual change of the climate, it becomes essential to understand the influence of genotype and the environment on plant phenotypes. Here, we intend to develop a machine learning (ML) model, which could predict the phenotype: Days to Flowering. Currently, our model can predict the phenotypic attributes in Sorghum bicolor and we intend to solve this problem in other plant species as well. The model takes the genetic data of the plants and environmental data as input. The gene data is based on Single Nucleotide Polymorphisms (SNP). It is filtered by entropy and added as features in the model. The environmental data consists of location of the plant (range and column of the subplot) and weather parameters from the weather station. Also, sowing date of the plants and window size are required to give as input parameter to the model. We use Extreme Gradient Boosting (XgBoost) regressor to model the data with 5-fold cross-validation and the script outputs a trained model which can be used to predict the phenotype.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64tkDCqvv5ha"
      },
      "source": [
        "**Dataset:**\n",
        "The following dataset is required in a particular format.\n",
        "\n",
        "**1. Trait Data of Plant Species:** Each observation in this dataset denotes the location (range and column) of the subplot, cultivar information, the date and days of flowering.\n",
        "\n",
        "*Columns: plot, range, column, scientificname, genotype, treatment, blocking_height, method, date_of_flowering, days_to_flowering, gdd_to_flowering, method_type*\n",
        "\n",
        "**2. Gene Data Filtered by Entropy:** The gene data comprises of SNPS from 4.4k genes present in 362 cultivars. The gene data is clustered using k-means with Euclidean distances for 30 gene clusters. Thus, the number of SNPs that each cultivar has in 30 gene clusters is added as features in the model.\n",
        "\n",
        "**3. Weather Data:** The weather data is obtained from a local weather station and the parameters include temperature, relative humidity, vapor pressure deficit, growing degree days and precipitation.\n",
        "\n",
        "*Columns: date, day_of_year, temp_min, temp_max, temp_mean, gdd, rh_min, rh_max, rh_mean, vpd_mean, precip, precip_cumulative, first_water_deficit_treatment, second_water_deficit_treatment*\n",
        "\n",
        "**4. Sowing Date:** The date at which the seeds of the plants were sowed.\n",
        "\n",
        "**5. Window Size:** The number of days from the sowing date for which the environmental variables are required to be used to train the model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XbkGDOEOhHB"
      },
      "source": [
        "The following script needs to be executed. In the first code block, neccesary user input is required. The cluster file (gene data filtered by entropy) is also required to be present with this python notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLWZwGgiywcS"
      },
      "source": [
        "# ***User input is required***\n",
        "# - Specify the URL/path of the trait data needs to be imported and the corresponding delimeter\n",
        "url_trait = \"/content/drive/MyDrive/GPE/MAC Season 4/mac_season_4_days_gdd_to_flowering.csv\"\n",
        "delim_trait = \",\"\n",
        "# - Specify the URL/path of the weather data needs to be imported and the corresponding delimeter\n",
        "weather_url = \"/content/drive/MyDrive/GPE/weather_data/mac_season_4_weather.csv\"\n",
        "weather_delim = ','\n",
        "# - Specify the sowing date\n",
        "sowing_date = \"2017-04-20\"\n",
        "# - Specify the window size\n",
        "window_size = 80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uITklTj3qAI3"
      },
      "source": [
        "#importing the relevant python packages\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import stats\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rWUuGNAhtH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27df44a-426b-4eca-fef1-2d4e9d923bc6"
      },
      "source": [
        "# This code block is not required to be executed if any github URL or a path on local machine is being provides as the path for the data. \n",
        "# Since, currently we are using Google Colab notebook and data is store on Google Drive, hence the drive location is mounted over here. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmWpASXcqAI7"
      },
      "source": [
        "# Importing the data \n",
        "fl = pd.read_csv(url_trait , delimiter = delim_trait)\n",
        "fl2=fl[['days_to_flowering', 'cultivar', 'range', 'column']]\n",
        "\n",
        "# Write about dist\n",
        "gene = pd.read_csv(\"/content/drive/MyDrive/GPE/Cluster.txt\", delimiter=\"\\t\")\n",
        "a = gene.X\n",
        "gene = gene.rename(columns={\"X\": \"cultivar\"})\n",
        "gene = gene.dropna()\n",
        "\n",
        "fl2=pd.merge(fl2, gene, on=\"cultivar\", how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnC0R-H2qAI-"
      },
      "source": [
        "# Import the weather data and calculate the average of weather paramaters between the sowing date and the window size (since weather data is at day level).\n",
        "mac=pd.read_csv(weather_url , delimiter= weather_delim)\n",
        "mac['date']=pd.to_datetime(mac.date)\n",
        "day_0=pd.to_datetime(sowing_date)\n",
        "day_n=day_0 + pd.to_timedelta(window_size, 'days')\n",
        "\n",
        "#for mean\n",
        "tmax = []\n",
        "tmean=[]\n",
        "tmin = []\n",
        "rhmax=[]\n",
        "rhmin=[]\n",
        "rhmean=[]\n",
        "vpd=[]\n",
        " \n",
        "for j in range(fl2.shape[0]):\n",
        "    li = (mac['date']>= day_0) & (mac['date'] <= day_n)\n",
        "    df_1 = mac[li]\n",
        "    tmax.append(df_1['temp_max'].mean())\n",
        "    tmin.append(df_1['temp_min'].mean())\n",
        "    tmean.append(df_1['temp_mean'].mean())\n",
        "    rhmax.append(df_1['rh_max'].mean())\n",
        "    rhmin.append(df_1['rh_min'].mean())\n",
        "    rhmean.append(df_1['rh_mean'].mean())\n",
        "    vpd.append(df_1['vpd_mean'].mean())\n",
        "\n",
        "fl2.insert(1,'temp_max_mean',tmax)\n",
        "fl2.insert(2,'temp_min_mean',tmin)\n",
        "fl2.insert(3,'temp_mean_mean',tmean)\n",
        "fl2.insert(4,'rh_max_mean',rhmax)\n",
        "fl2.insert(5,'rh_min_mean',rhmin)\n",
        "fl2.insert(6,'rh_mean_mean',rhmean)\n",
        "fl2.insert(7,'vpd_mean',vpd)\n",
        "\n",
        "#for maximum\n",
        "tmax = []\n",
        "tmean=[]\n",
        "tmin = []\n",
        "rhmax=[]\n",
        "rhmin=[]\n",
        "rhmean=[]\n",
        "vpd=[]\n",
        "\n",
        "\n",
        "for j in range(fl2.shape[0]):\n",
        "    li = (mac['date']>= day_0) & (mac['date'] <= day_n)\n",
        "    df_1 = mac[li]\n",
        "    tmax.append(df_1['temp_max'].max())\n",
        "    tmin.append(df_1['temp_min'].max())\n",
        "    tmean.append(df_1['temp_mean'].max())\n",
        "    rhmax.append(df_1['rh_max'].max())\n",
        "    rhmin.append(df_1['rh_min'].max())\n",
        "    rhmean.append(df_1['rh_mean'].max())\n",
        "    vpd.append(df_1['vpd_mean'].max())\n",
        "\n",
        "\n",
        "fl2.insert(1,'temp_max_max',tmax)\n",
        "fl2.insert(2,'temp_min_max',tmin)\n",
        "fl2.insert(3,'temp_mean_max',tmean)\n",
        "fl2.insert(4,'rh_max_max',rhmax)\n",
        "fl2.insert(5,'rh_min_max',rhmin)\n",
        "fl2.insert(6,'rh_mean_max',rhmean)\n",
        "fl2.insert(7,'vpd_max',vpd)\n",
        "\n",
        "#for minimum\n",
        "tmax = []\n",
        "tmean=[]\n",
        "tmin = []\n",
        "rhmax=[]\n",
        "rhmin=[]\n",
        "rhmean=[]\n",
        "vpd=[]\n",
        "\n",
        "for j in range(fl2.shape[0]):\n",
        "    li = (mac['date']>= day_0) & (mac['date'] <= day_n)\n",
        "    df_1 = mac[li]\n",
        "    tmax.append(df_1['temp_max'].min())\n",
        "    tmin.append(df_1['temp_min'].min())\n",
        "    tmean.append(df_1['temp_mean'].min())\n",
        "    rhmax.append(df_1['rh_max'].min())\n",
        "    rhmin.append(df_1['rh_min'].min())\n",
        "    rhmean.append(df_1['rh_mean'].min())\n",
        "    vpd.append(df_1['vpd_mean'].min())\n",
        "\n",
        "fl2.insert(1,'temp_max_min',tmax)\n",
        "fl2.insert(2,'temp_min_min',tmin)\n",
        "fl2.insert(3,'temp_mean_min',tmean)\n",
        "fl2.insert(4,'rh_max_min',rhmax)\n",
        "fl2.insert(5,'rh_min_min',rhmin)\n",
        "fl2.insert(6,'rh_mean_min',rhmean)\n",
        "fl2.insert(7,'vpd_min',vpd)\n",
        "\n",
        "gdd=[]\n",
        "pre=[]\n",
        "cpre=[]\n",
        "#for sum\n",
        "for j in range(fl2.shape[0]):\n",
        "    li = (mac['date']>= day_0) & (mac['date'] <= day_n)\n",
        "    df_1 = mac[li]\n",
        "    gdd.append(df_1['gdd'].sum())\n",
        "    pre.append(df_1['precip'].sum())\n",
        "    cpre.append(df_1['precip_cumulative'].sum())\n",
        "\n",
        "fl2.insert(8,'gdd_sum',gdd)\n",
        "fl2.insert(8,'precip_sum',pre)\n",
        "fl2.insert(8,'cumprecip_sum',cpre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAEI7LCDqAI_"
      },
      "source": [
        "new=fl2.drop(['cultivar', 'days_to_flowering'], axis=1)\n",
        "X=new.to_numpy()\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "y=fl2[['days_to_flowering']]\n",
        "y = np.asarray(y).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYodQt1uqAJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ea3484-6de1-44cb-9705-2c3cdeb84561"
      },
      "source": [
        "# Parameter tuning and 5 fold cross-validation for Extreme Gradient Boosting (XgBoost) Regression\n",
        "ns=5\n",
        "groups=fl2.cultivar\n",
        "cv =GroupKFold(n_splits=ns)\n",
        "\n",
        "model = xgb.XGBRegressor()\n",
        "groups=fl2.cultivar\n",
        "n_estimators = range(10, 60, 5)\n",
        "learning_rate = np.linspace(0,1,11)\n",
        "max_depth = range(1, 20, 2)\n",
        "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate)\n",
        "kfold = GroupKFold(n_splits=5)\n",
        "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=kfold)\n",
        "grid_result = grid_search.fit(X, y, groups)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "cv =GroupKFold(n_splits=ns)\n",
        "error=0\n",
        "e=[]\n",
        "for train_index, test_index in cv.split(X,y,groups):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "    clm=xgb.XGBRegressor(booster='gbtree',importance_type='gain',learning_rate= 0.2, max_depth= 3, n_estimators= 20).fit(X_train, y_train)\n",
        "    pred=clm.predict(X_test)\n",
        "    error=error+math.sqrt(mean_squared_error(y_test, pred))\n",
        "    e.append(math.sqrt(mean_squared_error(y_test, pred)))\n",
        "    \n",
        "std= (statistics.stdev(e))\n",
        "\n",
        "print('Root Mean square error for 5-fold CV XG:',error/ns, '+-', std)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Best: -10.520522 using {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 20}\n",
            "[21:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[21:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[21:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[21:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[21:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Root Mean square error for 5-fold CV XG: 10.520522366932623 +- 1.621935718989048\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}